{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=['Hey This is a new doc.','You are again in this plan','This is a new plan.','Hello how are you','','',''] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count vectorizer: \n",
      "  (0, 2)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 4)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 11)\t1\n",
      "  (1, 10)\t1\n",
      "  (2, 9)\t1\n",
      "  (2, 8)\t1\n",
      "  (2, 7)\t1\n",
      "  (2, 10)\t1\n",
      "  (3, 5)\t1\n",
      "  (3, 3)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 11)\t1\n"
     ]
    }
   ],
   "source": [
    "#count vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(text)\n",
    "X_train_counts.shape\n",
    "print('Count vectorizer: ')\n",
    "print(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfIdf :\n",
      "  (0, 10)\t0.36013879374975194\n",
      "  (0, 8)\t0.4213298560187446\n",
      "  (0, 7)\t0.4213298560187446\n",
      "  (0, 4)\t0.5075738143811802\n",
      "  (0, 2)\t0.5075738143811802\n",
      "  (1, 11)\t0.38827399235884513\n",
      "  (1, 10)\t0.3318837373022382\n",
      "  (1, 9)\t0.38827399235884513\n",
      "  (1, 6)\t0.4677515929889868\n",
      "  (1, 1)\t0.38827399235884513\n",
      "  (1, 0)\t0.4677515929889868\n",
      "  (2, 10)\t0.4425443423779347\n",
      "  (2, 9)\t0.5177369039159051\n",
      "  (2, 8)\t0.5177369039159051\n",
      "  (2, 7)\t0.5177369039159051\n",
      "  (3, 11)\t0.4516351457444982\n",
      "  (3, 5)\t0.544082434129559\n",
      "  (3, 3)\t0.544082434129559\n",
      "  (3, 1)\t0.4516351457444982\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape\n",
    "print('TfIdf :')\n",
    "print(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[0.36013879 0.42132986 0.42132986 0.50757381 0.50757381 0.38827399\n",
      " 0.33188374 0.38827399 0.46775159 0.38827399 0.46775159 0.44254434\n",
      " 0.5177369  0.5177369  0.5177369  0.45163515 0.54408243 0.54408243\n",
      " 0.45163515]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([16, 17, 14])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(X_train_tfidf.data))\n",
    "print(X_train_tfidf.data)\n",
    "(X_train_tfidf.data).argsort()[-3:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.544082434129559\n",
      "0.544082434129559\n",
      "0.5177369039159051\n"
     ]
    }
   ],
   "source": [
    "for i in (X_train_tfidf.data).argsort()[-3:][::-1]:\n",
    "    print(X_train_tfidf.data[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "X = tfidf.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=np.argsort(tfidf.idf_)[-3:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['again', 'are', 'doc', 'hello', 'hey', 'how', 'in', 'is', 'new', 'plan', 'this', 'you']\n",
      "['doc', 'are', 'again']\n"
     ]
    }
   ],
   "source": [
    "features = count_vect.get_feature_names()\n",
    "print(features)\n",
    "top_features = [features[i] for i in indices]\n",
    "print(top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "st='This is a new string'\n",
    "response = tfidf.transform([st])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = tfidf.fit_transform(text.split(' '))\n",
    "feature_array = np.array(tfidf.get_feature_names())\n",
    "tfidf_sorting = np.argsort(response.toarray()).flatten()[::-1]\n",
    "\n",
    "n = 3\n",
    "top_n = feature_array[tfidf_sorting][:n]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
