{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "bbcTextClassification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/singhmousam/DocumentClassificationUsingOCR/blob/master/bbcTextClassificationIncremental.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wngQdrk7mUSi",
        "colab_type": "code",
        "colab": {},
        "outputId": "b946e778-d4b2-4678-ec32-4822737ea3cc"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense, Dropout\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import sklearn.datasets as skds\n",
        "from pathlib import Path\n",
        "from keras.models import load_model\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZV6uiXJmUSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('bbc-text.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJ_CeunvmUSp",
        "colab_type": "code",
        "colab": {},
        "outputId": "9ced1235-3669-4104-c677-866bb3cfa872"
      },
      "source": [
        "set(data['category'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'business', 'entertainment', 'politics', 'sport', 'tech'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGAP6XCGmUSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# seperating data on basis of response variable\n",
        "#set1 = data[(data['category'] == 'entertainment') | (data['category'] == 'sport') | (data['category'] == 'tech')]\n",
        "#set2 = data[(data['category'] == 'politics') | (data['category'] == 'business')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmJpB3vSmUSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dividing whole data into sets\n",
        "set1 = data[0:500]\n",
        "set2 = data[500:1000]\n",
        "set3 = data[1000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eq_ry-QRmUSv",
        "colab_type": "text"
      },
      "source": [
        "## Training on Set1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-52ZsJ0LmUSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_1 = set1['text']\n",
        "tags_1 = set1['category']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpBcsG6QmUSx",
        "colab_type": "code",
        "colab": {},
        "outputId": "a3c44ad6-f789-4fb8-f8d0-53c37dd6ad6a"
      },
      "source": [
        "set(tags_1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'business', 'entertainment', 'politics', 'sport', 'tech'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAINOPrpmUSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_labels = 5\n",
        "vocab_size = 50000\n",
        "batch_size = 100\n",
        " \n",
        "# define Tokenizer with Vocab Size\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(text_1)\n",
        " \n",
        "x_train_1 = tokenizer.texts_to_matrix(text_1, mode='tfidf')\n",
        " \n",
        "encoder = LabelBinarizer()\n",
        "encoder.fit(tags_1)\n",
        "\n",
        "y_train_1 = encoder.transform(tags_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAsYXn_5mUS1",
        "colab_type": "code",
        "colab": {},
        "outputId": "162dbcb1-f93b-47c7-a47a-e53d62a7f1d3"
      },
      "source": [
        "encoder.classes_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['business', 'entertainment', 'politics', 'sport', 'tech'],\n",
              "      dtype='<U13')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBxojOmSmUS4",
        "colab_type": "code",
        "colab": {},
        "outputId": "8e47ba90-f911-4872-fa8a-498448195681"
      },
      "source": [
        "# model definition\n",
        "model1 = Sequential()\n",
        "model1.add(Dense(512, input_shape=(vocab_size,)))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(Dropout(0.3))\n",
        "model1.add(Dense(512))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(Dropout(0.3))\n",
        "model1.add(Dense(num_labels))\n",
        "model1.add(Activation('softmax'))\n",
        "model1.summary()\n",
        " \n",
        "model1.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "history = model1.fit(x_train_1, y_train_1,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /home/ikscare/anaconda3/envs/mspy36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /home/ikscare/anaconda3/envs/mspy36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 512)               25600512  \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 2565      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 25,865,733\n",
            "Trainable params: 25,865,733\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /home/ikscare/anaconda3/envs/mspy36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 450 samples, validate on 50 samples\n",
            "Epoch 1/10\n",
            "450/450 [==============================] - 6s 13ms/step - loss: 1.2043 - acc: 0.5467 - val_loss: 0.2694 - val_acc: 1.0000\n",
            "Epoch 2/10\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0653 - acc: 0.9933 - val_loss: 0.0605 - val_acc: 0.9800\n",
            "Epoch 3/10\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9600\n",
            "Epoch 4/10\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 6.9546e-05 - acc: 1.0000 - val_loss: 0.1155 - val_acc: 0.9600\n",
            "Epoch 5/10\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 7.8899e-05 - acc: 1.0000 - val_loss: 0.1667 - val_acc: 0.9600\n",
            "Epoch 6/10\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 2.1122e-06 - acc: 1.0000 - val_loss: 0.2078 - val_acc: 0.9400\n",
            "Epoch 7/10\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 2.6897e-05 - acc: 1.0000 - val_loss: 0.2397 - val_acc: 0.9400\n",
            "Epoch 8/10\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 1.3495e-05 - acc: 1.0000 - val_loss: 0.2611 - val_acc: 0.9400\n",
            "Epoch 9/10\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 1.0640e-06 - acc: 1.0000 - val_loss: 0.2709 - val_acc: 0.9400\n",
            "Epoch 10/10\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 5.9513e-07 - acc: 1.0000 - val_loss: 0.2770 - val_acc: 0.9400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi1jxCERmUS7",
        "colab_type": "code",
        "colab": {},
        "outputId": "5395612e-7e9d-4616-9354-a482f8bd07c4"
      },
      "source": [
        "model1.layers[:-2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.layers.core.Dense at 0x7f056dce37f0>,\n",
              " <keras.layers.core.Activation at 0x7f056dce3390>,\n",
              " <keras.layers.core.Dropout at 0x7f05640d56a0>,\n",
              " <keras.layers.core.Dense at 0x7f05640d5438>,\n",
              " <keras.layers.core.Activation at 0x7f05640d5b38>,\n",
              " <keras.layers.core.Dropout at 0x7f0564081e10>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC2VCKRkmUS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# freezing layers\n",
        "for layer in model1.layers[:-2]:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-CTrcNImUS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.save('bbcmodel1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ytL7sM4mUTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_labels = encoder.classes_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7R1CM8smUTC",
        "colab_type": "text"
      },
      "source": [
        "## Testing on Set1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbbGIBtwmUTD",
        "colab_type": "code",
        "colab": {},
        "outputId": "6ee1ab6b-1bb6-4e35-b3c8-e54f73703841"
      },
      "source": [
        "count = 0\n",
        "for i in range(500):\n",
        "    prediction = model1.predict(np.array([x_train_1[i]]))\n",
        "    predicted_label = text_labels[np.argmax(prediction[0])]\n",
        "    if tags_1.iloc[i] != predicted_label:\n",
        "        count+=1\n",
        "        #print('Actual label:' + tags_1.iloc[i])\n",
        "        #print(\"Predicted label: \" + predicted_label)\n",
        "count"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaGPa3lRmUTF",
        "colab_type": "text"
      },
      "source": [
        "## Testing on Set2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAwFVZBSmUTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_2 = set2['text']\n",
        "tags_2 = set2['category']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdoPYHtImUTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_2 = tokenizer.texts_to_matrix(text_2, mode='tfidf')\n",
        "encoder.fit(tags_2)\n",
        "y_train_2 = encoder.transform(tags_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRiERhyOmUTM",
        "colab_type": "code",
        "colab": {},
        "outputId": "98da84a4-dfdd-4151-deea-08db3c7d010b"
      },
      "source": [
        "text_labels = encoder.classes_\n",
        "text_labels"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['business', 'entertainment', 'politics', 'sport', 'tech'],\n",
              "      dtype='<U13')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6096d1HmUTO",
        "colab_type": "code",
        "colab": {},
        "outputId": "919c3ab6-902c-4040-c8a2-a63936d90cde"
      },
      "source": [
        "# Set2\n",
        "count = 0\n",
        "for i in range(500):\n",
        "    prediction = model1.predict(np.array([x_train_2[i]]))\n",
        "    predicted_label = text_labels[np.argmax(prediction[0])]\n",
        "    if tags_2.iloc[i] != predicted_label:\n",
        "        count+=1\n",
        "        #print('Actual label:' + tags_2.iloc[i])\n",
        "        #print(\"Predicted label: \" + predicted_label)\n",
        "count"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6id2vd5HmUTT",
        "colab_type": "text"
      },
      "source": [
        "## Model trained on set2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L2zh0KSmUTU",
        "colab_type": "code",
        "colab": {},
        "outputId": "722eb529-684a-4404-fd0d-c5326aee5fba"
      },
      "source": [
        "# model definition\n",
        "modelset2 = Sequential()\n",
        "modelset2.add(Dense(512, input_shape=(vocab_size,)))\n",
        "modelset2.add(Activation('relu'))\n",
        "modelset2.add(Dropout(0.3))\n",
        "modelset2.add(Dense(512))\n",
        "modelset2.add(Activation('relu'))\n",
        "modelset2.add(Dropout(0.3))\n",
        "modelset2.add(Dense(num_labels)) # num_labels\n",
        "modelset2.add(Activation('softmax'))\n",
        "modelset2.summary()\n",
        " \n",
        "modelset2.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "history = modelset2.fit(x_train_2, y_train_2,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 512)               25600512  \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 5)                 2565      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 25,865,733\n",
            "Trainable params: 25,865,733\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 450 samples, validate on 50 samples\n",
            "Epoch 1/10\n",
            "450/450 [==============================] - 3s 6ms/step - loss: 1.1328 - acc: 0.6467 - val_loss: 0.3034 - val_acc: 0.9400\n",
            "Epoch 2/10\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0497 - acc: 0.9956 - val_loss: 0.1025 - val_acc: 0.9600\n",
            "Epoch 3/10\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 8.5738e-04 - acc: 1.0000 - val_loss: 0.1542 - val_acc: 0.9600\n",
            "Epoch 4/10\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 8.1844e-05 - acc: 1.0000 - val_loss: 0.2104 - val_acc: 0.9600\n",
            "Epoch 5/10\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 1.0399e-05 - acc: 1.0000 - val_loss: 0.2466 - val_acc: 0.9600\n",
            "Epoch 6/10\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 1.1791e-04 - acc: 1.0000 - val_loss: 0.2656 - val_acc: 0.9600\n",
            "Epoch 7/10\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 1.1388e-05 - acc: 1.0000 - val_loss: 0.2593 - val_acc: 0.9600\n",
            "Epoch 8/10\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 1.8125e-05 - acc: 1.0000 - val_loss: 0.2580 - val_acc: 0.9600\n",
            "Epoch 9/10\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 9.5482e-07 - acc: 1.0000 - val_loss: 0.2580 - val_acc: 0.9600\n",
            "Epoch 10/10\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 3.4028e-07 - acc: 1.0000 - val_loss: 0.2582 - val_acc: 0.9600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3MzC9u1mUTZ",
        "colab_type": "text"
      },
      "source": [
        "## Re-Training on set2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpbEfAKNmUTZ",
        "colab_type": "code",
        "colab": {},
        "outputId": "fc049c00-22f2-4d4d-f244-0226422c57a3"
      },
      "source": [
        "model2 = load_model('bbcmodel1')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/ikscare/anaconda3/envs/mspy36/lib/python3.6/site-packages/keras/engine/saving.py:327: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "  warnings.warn('Error in loading the saved optimizer '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOLV7oLCmUTd",
        "colab_type": "code",
        "colab": {},
        "outputId": "21868654-2f17-437b-ad65-1cf48e9b5508"
      },
      "source": [
        "model2.fit(x_train_2, y_train_2,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 450 samples, validate on 50 samples\n",
            "Epoch 1/10\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.2498 - acc: 0.9422 - val_loss: 0.1514 - val_acc: 0.9600\n",
            "Epoch 2/10\n",
            "450/450 [==============================] - 0s 737us/step - loss: 0.1834 - acc: 0.9644 - val_loss: 0.1186 - val_acc: 0.9600\n",
            "Epoch 3/10\n",
            "450/450 [==============================] - 0s 729us/step - loss: 0.1414 - acc: 0.9667 - val_loss: 0.1239 - val_acc: 0.9600\n",
            "Epoch 4/10\n",
            "450/450 [==============================] - 0s 728us/step - loss: 0.1256 - acc: 0.9667 - val_loss: 0.1351 - val_acc: 0.9800\n",
            "Epoch 5/10\n",
            "450/450 [==============================] - 0s 729us/step - loss: 0.1528 - acc: 0.9667 - val_loss: 0.1341 - val_acc: 0.9800\n",
            "Epoch 6/10\n",
            "450/450 [==============================] - 0s 821us/step - loss: 0.1556 - acc: 0.9644 - val_loss: 0.1214 - val_acc: 0.9800\n",
            "Epoch 7/10\n",
            "450/450 [==============================] - 0s 741us/step - loss: 0.1470 - acc: 0.9756 - val_loss: 0.1097 - val_acc: 0.9800\n",
            "Epoch 8/10\n",
            "450/450 [==============================] - 0s 740us/step - loss: 0.1396 - acc: 0.9667 - val_loss: 0.0991 - val_acc: 0.9800\n",
            "Epoch 9/10\n",
            "450/450 [==============================] - 0s 714us/step - loss: 0.1334 - acc: 0.9711 - val_loss: 0.0946 - val_acc: 0.9600\n",
            "Epoch 10/10\n",
            "450/450 [==============================] - 0s 728us/step - loss: 0.1177 - acc: 0.9689 - val_loss: 0.0905 - val_acc: 0.9600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7eff570595c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBqZyp4smUTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2.save('bbcmodel2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKSpDUlhmUTj",
        "colab_type": "text"
      },
      "source": [
        "### Predicting model2 on set2 and set1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8xRVovOmUTk",
        "colab_type": "code",
        "colab": {},
        "outputId": "18ce6b79-51e3-46bb-d60d-a0ea4ddd3b38"
      },
      "source": [
        "# Set2\n",
        "count = 0\n",
        "for i in range(500):\n",
        "    prediction = model2.predict(np.array([x_train_2[i]]))\n",
        "    predicted_label = text_labels[np.argmax(prediction[0])]\n",
        "    if tags_2.iloc[i] != predicted_label:\n",
        "        count+=1\n",
        "        #print('Actual label:' + tags_2.iloc[i])\n",
        "        #print(\"Predicted label: \" + predicted_label)\n",
        "count"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTuBpOqEmUTm",
        "colab_type": "code",
        "colab": {},
        "outputId": "ed9d39ea-c589-4dd7-8011-5000f0f08a25"
      },
      "source": [
        "# Set1\n",
        "count = 0\n",
        "for i in range(500):\n",
        "    prediction = model2.predict(np.array([x_train_1[i]]))\n",
        "    predicted_label = text_labels[np.argmax(prediction[0])]\n",
        "    if tags_1.iloc[i] != predicted_label:\n",
        "        count+=1\n",
        "        #print('Actual label:' + tags_1.iloc[i])\n",
        "        #print(\"Predicted label: \" + predicted_label)\n",
        "count"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9z9b6cCmUTn",
        "colab_type": "text"
      },
      "source": [
        "### Predicting modelset2 on SET 1 and SET 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3s389tQmUTo",
        "colab_type": "code",
        "colab": {},
        "outputId": "021cacfa-9b52-4169-b79b-c3853fd64fe8"
      },
      "source": [
        "# Set2\n",
        "count = 0\n",
        "for i in range(500):\n",
        "    prediction = modelset2.predict(np.array([x_train_2[i]]))\n",
        "    predicted_label = text_labels[np.argmax(prediction[0])]\n",
        "    if tags_2.iloc[i] != predicted_label:\n",
        "        count+=1\n",
        "        #print('Actual label:' + tags_2.iloc[i])\n",
        "        #print(\"Predicted label: \" + predicted_label)\n",
        "count"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSSmKaYXmUTq",
        "colab_type": "code",
        "colab": {},
        "outputId": "3c34687f-0e48-4d2f-de13-e1cc94b45c7f"
      },
      "source": [
        "# Set1\n",
        "count = 0\n",
        "for i in range(500):\n",
        "    prediction = modelset2.predict(np.array([x_train_1[i]]))\n",
        "    predicted_label = text_labels[np.argmax(prediction[0])]\n",
        "    if tags_1.iloc[i] != predicted_label:\n",
        "        count+=1\n",
        "        #print('Actual label:' + tags_1.iloc[i])\n",
        "        #print(\"Predicted label: \" + predicted_label)\n",
        "count"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWHa-7z_mUTs",
        "colab_type": "text"
      },
      "source": [
        "## Testing on set3 using both models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMeSm0W5mUTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_3 = set3['text']\n",
        "tags_3 = set3['category']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw1XAnCEmUTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_3 = tokenizer.texts_to_matrix(text_3, mode='tfidf')\n",
        "y_train_3 = encoder.transform(tags_3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc9TGHZumUTw",
        "colab_type": "code",
        "colab": {},
        "outputId": "a1725cd9-1bb7-4614-a030-f9ff36a72d33"
      },
      "source": [
        "count = 0\n",
        "for i in range(1000):\n",
        "    prediction = model1.predict(np.array([x_train_3[i]]))\n",
        "    predicted_label = text_labels[np.argmax(prediction[0])]\n",
        "    if tags_3.iloc[i] != predicted_label:\n",
        "        count+=1\n",
        "        #print('Actual label:' + tags_3.iloc[i])\n",
        "        #print(\"Predicted label: \" + predicted_label)\n",
        "count"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9eY_Hz1mUTy",
        "colab_type": "code",
        "colab": {},
        "outputId": "29fa90e5-ade6-46a4-c203-3a192b80b0b4"
      },
      "source": [
        "count = 0\n",
        "for i in range(1000):\n",
        "    prediction = model2.predict(np.array([x_train_3[i]]))\n",
        "    predicted_label = text_labels[np.argmax(prediction[0])]\n",
        "    if tags_3.iloc[i] != predicted_label:\n",
        "        count+=1\n",
        "        #print('Actual label:' + tags_3.iloc[i])\n",
        "        #print(\"Predicted label: \" + predicted_label)\n",
        "count"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3WluFWgmUT0",
        "colab_type": "code",
        "colab": {},
        "outputId": "b3c92cd8-44f5-4306-876e-c73d6f602a74"
      },
      "source": [
        "count = 0\n",
        "for i in range(1000):\n",
        "    prediction = modelset2.predict(np.array([x_train_3[i]]))\n",
        "    predicted_label = text_labels[np.argmax(prediction[0])]\n",
        "    if tags_3.iloc[i] != predicted_label:\n",
        "        count+=1\n",
        "        #print('Actual label:' + tags_3.iloc[i])\n",
        "        #print(\"Predicted label: \" + predicted_label)\n",
        "count"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHQfg20GmUT3",
        "colab_type": "text"
      },
      "source": [
        "## Retraining the model on set3 of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y80qDwN9mUT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3 = load_model('bbcmodel2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12C7mwHLmUT6",
        "colab_type": "code",
        "colab": {},
        "outputId": "86fced0e-5f6f-4fad-ffec-e8ec222a12dd"
      },
      "source": [
        "model3.fit(x_train_3, y_train_3,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1102 samples, validate on 123 samples\n",
            "Epoch 1/10\n",
            "1102/1102 [==============================] - 1s 1ms/step - loss: 0.2014 - acc: 0.9492 - val_loss: 0.2860 - val_acc: 0.9593\n",
            "Epoch 2/10\n",
            "1102/1102 [==============================] - 1s 709us/step - loss: 0.1788 - acc: 0.9628 - val_loss: 0.2914 - val_acc: 0.9431\n",
            "Epoch 3/10\n",
            "1102/1102 [==============================] - 1s 717us/step - loss: 0.1752 - acc: 0.9574 - val_loss: 0.3044 - val_acc: 0.9431\n",
            "Epoch 4/10\n",
            "1102/1102 [==============================] - 1s 714us/step - loss: 0.1665 - acc: 0.9564 - val_loss: 0.2938 - val_acc: 0.9350\n",
            "Epoch 5/10\n",
            "1102/1102 [==============================] - 1s 722us/step - loss: 0.1721 - acc: 0.9601 - val_loss: 0.2820 - val_acc: 0.9431\n",
            "Epoch 6/10\n",
            "1102/1102 [==============================] - 1s 719us/step - loss: 0.1738 - acc: 0.9610 - val_loss: 0.3049 - val_acc: 0.9431\n",
            "Epoch 7/10\n",
            "1102/1102 [==============================] - 1s 715us/step - loss: 0.1348 - acc: 0.9673 - val_loss: 0.2896 - val_acc: 0.9512\n",
            "Epoch 8/10\n",
            "1102/1102 [==============================] - 1s 721us/step - loss: 0.1513 - acc: 0.9592 - val_loss: 0.3062 - val_acc: 0.9431\n",
            "Epoch 9/10\n",
            "1102/1102 [==============================] - 1s 730us/step - loss: 0.1333 - acc: 0.9655 - val_loss: 0.2902 - val_acc: 0.9350\n",
            "Epoch 10/10\n",
            "1102/1102 [==============================] - 1s 726us/step - loss: 0.1681 - acc: 0.9637 - val_loss: 0.2799 - val_acc: 0.9350\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7eff55fe00b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dJ7NoSsmUT7",
        "colab_type": "text"
      },
      "source": [
        "## prediction of model3 on all sets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "766YMMm7mUT8",
        "colab_type": "code",
        "colab": {},
        "outputId": "4db1a0f0-1e09-41c3-b125-d35bdc135e37"
      },
      "source": [
        "# set3\n",
        "count = 0\n",
        "for i in range(1000):\n",
        "    prediction = model3.predict(np.array([x_train_3[i]]))\n",
        "    predicted_label = text_labels[np.argmax(prediction[0])]\n",
        "    if tags_3.iloc[i] != predicted_label:\n",
        "        count+=1\n",
        "        #print('Actual label:' + tags_3.iloc[i])\n",
        "        #print(\"Predicted label: \" + predicted_label)\n",
        "count"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c81NfmqEmUT9",
        "colab_type": "code",
        "colab": {},
        "outputId": "23a6b72e-49f2-4425-f511-41c034af091a"
      },
      "source": [
        "# SET2\n",
        "count = 0\n",
        "for i in range(499):\n",
        "    prediction = model3.predict(np.array([x_train_2[i]]))\n",
        "    predicted_label = text_labels[np.argmax(prediction[0])]\n",
        "    if tags_2.iloc[i] != predicted_label:\n",
        "        count+=1\n",
        "        #print('Actual label:' + tags_3.iloc[i])\n",
        "        #print(\"Predicted label: \" + predicted_label)\n",
        "count"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdxRIGdUmUUA",
        "colab_type": "code",
        "colab": {},
        "outputId": "4bbdb2e2-8196-4b81-83e9-f58fb98880f6"
      },
      "source": [
        "# SET1\n",
        "count = 0\n",
        "for i in range(499):\n",
        "    prediction = model3.predict(np.array([x_train_1[i]]))\n",
        "    predicted_label = text_labels[np.argmax(prediction[0])]\n",
        "    if tags_1.iloc[i] != predicted_label:\n",
        "        count+=1\n",
        "        #print('Actual label:' + tags_3.iloc[i])\n",
        "        #print(\"Predicted label: \" + predicted_label)\n",
        "count"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8eSAx1smUUE",
        "colab_type": "text"
      },
      "source": [
        "# Preparing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu2I6R-WmUUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "set1 = data[(data['category'] == 'entertainment') | (data['category'] == 'sport') | (data['category'] == 'tech') | (data['category'] == 'business')]\n",
        "set2 = data[(data['category'] == 'politics') | (data['category'] == 'business') | (data['category'] == 'tech') | (data['category'] == 'sport')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTAe0rzVmUUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_1 = set1['text']\n",
        "tags_1 = set1['category']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qa66D13mUUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_labels = 5\n",
        "vocab_size = 50000\n",
        "batch_size = 100\n",
        " \n",
        "# define Tokenizer with Vocab Size\n",
        "#tokenizer.fit_on_texts(text_1)\n",
        " \n",
        "x_train_1 = tokenizer.texts_to_matrix(text_1, mode='tfidf')\n",
        " \n",
        "#encoder = LabelBinarizer()\n",
        "#encoder.fit(tags_1)\n",
        "\n",
        "y_train_1 = encoder.transform(tags_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIJjuYiWmUUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model definition\n",
        "model1 = Sequential()\n",
        "model1.add(Dense(512, input_shape=(vocab_size,)))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(Dropout(0.3))\n",
        "model1.add(Dense(512))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(Dropout(0.3))\n",
        "model1.add(Dense(num_labels))\n",
        "model1.add(Activation('softmax'))\n",
        "model1.summary()\n",
        " \n",
        "model1.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "history = model1.fit(x_train_1, y_train_1,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGQ3IKG4mUUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_labels = encoder.classes_\n",
        "text_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zwt0w4WmUUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prediction on set1\n",
        "count = 0\n",
        "for i in range(500):\n",
        "    prediction = modelset2.predict(np.array([x_train_1[i]]))\n",
        "    predicted_label = text_labels[np.argmax(prediction[0])]\n",
        "    if tags_1.iloc[i] != predicted_label:\n",
        "        count+=1\n",
        "        #print('Actual label:' + tags_1.iloc[i])\n",
        "        #print(\"Predicted label: \" + predicted_label)\n",
        "count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5njD7s8XmUUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_2 = set2['text']\n",
        "tags_2 = set2['category']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nVSkfYemUUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_2 = tokenizer.texts_to_matrix(text_2, mode='tfidf')\n",
        "#encoder = LabelBinarizer()\n",
        "#encoder.fit(tags_2)\n",
        "y_train_2 = encoder.transform(tags_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAPAWxxvmUUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_labels = encoder.classes_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnGnKeaLmUUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set2\n",
        "count = 0\n",
        "for i in range(500):\n",
        "    prediction = modelset2.predict(np.array([x_train_2[i]]))\n",
        "    predicted_label = text_labels[np.argmax(prediction[0])]\n",
        "    if tags_2.iloc[i] != predicted_label:\n",
        "        count+=1\n",
        "        #print('Actual label:' + tags_2.iloc[i])\n",
        "        #print(\"Predicted label: \" + predicted_label)\n",
        "count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taiWhaN8mUUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.fit(x_train_2, y_train_2,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY7O2XYAmUUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model definition\n",
        "modelset2 = Sequential()\n",
        "modelset2.add(Dense(512, input_shape=(vocab_size,)))\n",
        "modelset2.add(Activation('relu'))\n",
        "modelset2.add(Dropout(0.3))\n",
        "modelset2.add(Dense(512))\n",
        "modelset2.add(Activation('relu'))\n",
        "modelset2.add(Dropout(0.3))\n",
        "modelset2.add(Dense(num_labels)) # num_labels\n",
        "modelset2.add(Activation('softmax'))\n",
        "modelset2.summary()\n",
        " \n",
        "modelset2.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "history = modelset2.fit(x_train_2, y_train_2,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8x6C8sYmUUj",
        "colab_type": "text"
      },
      "source": [
        "# Trial sklearn library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWQTHwlKmUUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "text_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', MultinomialNB()),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7ySM0AsmUUk",
        "colab_type": "code",
        "colab": {},
        "outputId": "be7f8562-eeca-4008-976e-18537b686912"
      },
      "source": [
        "y_train_1[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCaYi84smUUl",
        "colab_type": "code",
        "colab": {},
        "outputId": "d7bd629a-8c80-4a78-8f83-1e691fe8f1fa"
      },
      "source": [
        "x_train_1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 50000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjHYN5l3mUUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clfobj = MultinomialNB()\n",
        "ovr = OneVsRestClassifier(clfobj)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32wo_SyYmUUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = ovr.fit(x_train_1,y_train_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4eZdBhMmUUr",
        "colab_type": "code",
        "colab": {},
        "outputId": "7646011e-403f-4ffa-c014-6f0f606f7b81"
      },
      "source": [
        "hex(id(clf))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0x7f0567d5d6d8'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbN8Ep7XmUUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf3 = clf.fit(x_train_2,y_train_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BMejH4xmUUv",
        "colab_type": "code",
        "colab": {},
        "outputId": "a57c1e0f-e0f3-4925-fb1f-f8ff2f68ff56"
      },
      "source": [
        "hex(id(clf3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0x7f0567d5d6d8'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCy5lccvmUUw",
        "colab_type": "code",
        "colab": {},
        "outputId": "8b3053fb-a582-4422-ed01-98360051219e"
      },
      "source": [
        "# Set2\n",
        "count = 0\n",
        "for i in range(500):\n",
        "    prediction = clf.predict(np.array([x_train_1[i]]))\n",
        "    predicted_label = text_labels[np.argmax(prediction[0])]\n",
        "    if tags_1.iloc[i] != predicted_label:\n",
        "        count+=1\n",
        "        #print('Actual label:' + tags_2.iloc[i])\n",
        "        #print(\"Predicted label: \" + predicted_label)\n",
        "count"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys-trQpNmUUx",
        "colab_type": "code",
        "colab": {},
        "outputId": "73dd611a-57dc-42b6-d169-983e348bd0ab"
      },
      "source": [
        "# Set2\n",
        "count = 0\n",
        "for i in range(500):\n",
        "    prediction = clf.predict(np.array([x_train_2[i]]))\n",
        "    predicted_label = text_labels[np.argmax(prediction[0])]\n",
        "    if tags_2.iloc[i] != predicted_label:\n",
        "        count+=1\n",
        "        #print('Actual label:' + tags_2.iloc[i])\n",
        "        #print(\"Predicted label: \" + predicted_label)\n",
        "count"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVLv5HgdmUUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf2 = ovr.fit(x_train_2,y_train_2)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}